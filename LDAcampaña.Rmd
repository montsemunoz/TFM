---
title: "LDA"
author: "Montse Muñoz Aragón"
date: "25/5/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE, warning=FALSE}
library(stringr)
library(devtools)
library(dplyr)
library(purrr)
library(tidyr)
library(stopwords)
library(tm)
library(quanteda)
library(e1071)
library(readxl)
library(lubridate)
library(ggplot2)
library(wordcloud)
library(RColorBrewer)
library(gridExtra)
library(scales)
library(tidytext)
library(igraph)
library(ggraph)
library(forcats)
library(topicmodels)
library(textmineR)
library(BullsEyeR)
library(ldatuning)
```

```{r}
load("Limpieza datos y análisis (campaña).RData")
```

```{r}
corpus <- Corpus(VectorSource(M$palabras))

doc.lengths <- rowSums(as.matrix(DocumentTermMatrix(corpus)))
dtm <- DocumentTermMatrix(corpus[doc.lengths > 0]) #documents== tweets cada partido, terms== palabras
```

- Número de tópicos

```{r}
result <- FindTopicsNumber(
dtm,
topics = seq(from = 2, to = 14, by = 1),
metrics = c("CaoJuan2009","Deveaud2014"),
method = "Gibbs",
control = list(seed = 77),
mc.cores = NA,
verbose = TRUE)
```

```{r}
FindTopicsNumber_plot(result)
```

### Gibbs

- LDA

```{r}
t <- proc.time()
lda_6g <- LDA(dtm, k = 6, method = 'Gibbs', control = list(seed = list(1505)))
proc.time()-t

```

```{r}
t <- proc.time()
lda_12g <- LDA(dtm, k = 12, method = 'Gibbs', control = list(seed = list(1505)))
proc.time()-t
```

```{r}
terms(lda_6g,5)

terms(lda_12g,5)
```

- Probabilidad de que una palabra pertenezca a un tópico

```{r}
lda_td6g <- tidy(lda_6g, matrix = "beta")

lda_td12g <- tidy(lda_12g, matrix = "beta")
```

```{r}
terminos_frecuentes6g <- lda_td6g %>% group_by(topic) %>%  ungroup() %>% arrange(topic, -beta)
top6g <- terminos_frecuentes6g %>% group_by(topic) %>% top_n(10, beta)

terminos_frecuentes12g <- lda_td12g %>% group_by(topic) %>% ungroup() %>% arrange(topic, -beta)
top12g <- terminos_frecuentes12g %>% group_by(topic) %>% top_n(10, beta)

```

- Histograma de top 10 palabras en cada tópico

```{r}
ap_top_terms6g <- lda_td6g %>% group_by(topic) %>% slice_max(beta, n = 10) %>% ungroup() %>% arrange(topic, -beta)

#ap_top_terms6g <- lda_td6g %>% group_by(topic)  %>% filter(beta>0.006) %>% ungroup() %>% arrange(topic, -beta)

ap_top_terms6g %>% mutate(term = reorder_within(term, beta, topic)) %>% ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) + facet_wrap(~ topic, scales = "free") + scale_y_reordered()
```

```{r}
ap_top_terms12g <- lda_td12g %>% group_by(topic) %>% slice_max(beta, n = 10) %>% ungroup() %>% arrange(topic, -beta)

ap_top_terms12g %>% mutate(term = reorder_within(term, beta, topic)) %>% ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) + facet_wrap(~ topic, scales = "free") + scale_y_reordered()
```

- Probabilidad de que un documento pertenzeca a un tópico

```{r}
lda_gamma6g <- tidy(lda_6g, matrix = "gamma")

lda_gamma12g <- tidy(lda_12g, matrix = "gamma")
```

- Entropía tópicos por documento

```{r}
sum <- 0
v <- c()

doc <- c(1:5)

for( i in 1:length(doc)){
  
  documento <- lda_gamma6g[lda_gamma6g$document==i,]
  
  for (j in 1:nrow(documento)){
  
    sum <- sum + (documento$gamma[j]*log(1/documento$gamma[j]))
  }
  
  v <- c(v,sum)
  sum <- 0
}
v
```

- Entropía palabras por tópico

```{r}
sum <- 0
v <- c()

top <- c(1:6)

for( i in 1:length(top)){
  
  topico <- terminos_frecuentes6g[terminos_frecuentes6g$topic==i,]
  
  for (j in 1:nrow(topico)){
  
    sum <- sum + (topico$beta[j]*log(1/topico$beta[j]))
  }
  
  v <- c(v,sum)
  sum <- 0
}
v
```

- Heatmap de tópicos por partido

```{r}
topics <- topicmodels::posterior(lda_6g, dtm)[["topics"]]
rownames(topics) <- c("VOX","PP","C's","PSOE","UP")
colnames(topics) <- c("Tópico 1","Tópico 2","Tópico 3","Tópico 4","Tópico 5","Tópico 6")
#colores <- colorRampPalette(c("grey", "white", "steelblue"))(256)
colores <- colorRampPalette(brewer.pal(8, "Blues"))(25)
heatmap(topics, scale = "none",col= colores, cexRow = 1.3, cexCol = 1.3)
```

- Wordcloud con 6 tópicos

```{r warning=FALSE}

for(i in 1:6){
df <- data.frame(term = lda_6g@terms, p = exp(lda_6g@beta[i,]))
wordcloud(words = df$term,
          freq = df$p,
          max.words = 300,
          random.order = FALSE,
          rot.per = 0.15,
          colors=brewer.pal(8, "Dark2"))
}

```

### Inferencia variacional

- LDA

```{r}
t <- proc.time()
lda_6i <- LDA(dtm, k = 6, method = 'VEM', control = list(seed = list(1505)))
proc.time()-t
```

```{r}
t <- proc.time()
lda_12i <- LDA(dtm, k = 12, method = 'VEM', control = list(seed = list(1505)))
proc.time()-t
```

```{r}
terms(lda_6i,5)

terms(lda_12i,5)
```

- Probabilidad de que una palabra pertenezca a un tópico

```{r}
lda_td6i <- tidy(lda_6i, matrix = "beta")

lda_td12i <- tidy(lda_12i, matrix = "beta")
```

```{r}
terminos_frecuentes6i <- lda_td6i %>% group_by(topic) %>% top_n(10, beta) %>% ungroup() %>% arrange(topic, -beta)

terminos_frecuentes12i <- lda_td12i %>% group_by(topic) %>% top_n(10, beta) %>% ungroup() %>% arrange(topic, -beta)
```

- Histograma de top 10 palabras en cada tópico

```{r}
ap_top_terms6i <- lda_td6i %>% group_by(topic) %>% slice_max(beta, n = 10) %>% ungroup() %>% arrange(topic, -beta)

ap_top_terms6i %>% mutate(term = reorder_within(term, beta, topic)) %>% ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) + facet_wrap(~ topic, scales = "free", ncol=3) + scale_y_reordered()
```

```{r}
ap_top_terms12i <- lda_td12i %>% group_by(topic) %>% slice_max(beta, n = 10) %>% ungroup() %>% arrange(topic, -beta)

ap_top_terms12i %>% mutate(term = reorder_within(term, beta, topic)) %>% ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) + facet_wrap(~ topic, scales = "free", ncol=4) + scale_y_reordered()
```

- Probabilidad de que un documento pertenzeca a un tópico

```{r}
options(scipen=999)
lda_gamma6i <- tidy(lda_6i, matrix = "gamma")

lda_gamma12i <- tidy(lda_12i, matrix = "gamma")
```
